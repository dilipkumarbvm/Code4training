{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# üìù Prompt Templates Demo\n",
        "\n",
        "**Learn how different prompt template styles affect AI responses!**\n",
        "\n",
        "This notebook demonstrates how to create and use different types of prompt templates in LangChain. We'll use the same topic (**\"artificial intelligence\"**) across all demonstrations to show how template structure affects the AI's response style.\n",
        "\n",
        "## üéØ What You'll Learn\n",
        "\n",
        "1. **Basic String Templates** - Simple variable substitution\n",
        "2. **Chat Templates** - System + user message structure  \n",
        "3. **Templates with History** - Including conversation context\n",
        "4. **Complex Instructions** - Detailed formatting guidelines\n",
        "\n",
        "**Key Insight:** The way you structure your prompts dramatically changes the AI's response style, tone, and comprehensiveness!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Configuration\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Get OpenAI API key\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    print(\"‚ö†Ô∏è  Warning: OPENAI_API_KEY not found in environment variables\")\n",
        "    print(\"Please set your OpenAI API key in a .env file or environment variable\")\n",
        "    print(\"Get your key from: https://platform.openai.com/api-keys\")\n",
        "else:\n",
        "    print(\"‚úÖ OpenAI API key loaded successfully!\")\n",
        "\n",
        "# Topic we'll use for all demonstrations (change this to explore different topics!)\n",
        "TOPIC = \"artificial intelligence\"\n",
        "\n",
        "print(f\"üéØ Setup complete! Topic for all demos: '{TOPIC}'\")\n",
        "print(\"üí° Feel free to change the TOPIC variable above and re-run all cells to see different responses!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üîó 1. Basic String Template\n",
        "\n",
        "**Definition:** Simple template with variable placeholders using `{variable}` syntax.\n",
        "\n",
        "**Characteristics:**\n",
        "- ‚úÖ **Simple and straightforward** - Easy to understand and use\n",
        "- ‚úÖ **Direct variable substitution** - `{topic}` gets replaced with actual value\n",
        "- ‚úÖ **Good for basic queries** - When you just need information\n",
        "- ‚ùå **Limited control** - No role specification or detailed instructions\n",
        "\n",
        "**When to use:** Simple, direct questions where you just need basic information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîó Basic String Template Demo\n",
        "\n",
        "print(\"üîó BASIC STRING TEMPLATE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create a simple template with one variable placeholder {topic}\n",
        "# The {} syntax tells LangChain where to substitute values\n",
        "template = PromptTemplate.from_template(\"Tell me a fact about {topic}\")\n",
        "\n",
        "print(f\"Template: {template.template}\")\n",
        "print(f\"Variables: {template.input_variables}\")\n",
        "\n",
        "# Connect template to LLM to see actual response\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=80, openai_api_key=OPENAI_API_KEY)\n",
        "chain = template | model\n",
        "\n",
        "print(f\"\\nüìù Topic: {TOPIC}\")\n",
        "print(\"ü§ñ LLM Response:\")\n",
        "\n",
        "result = chain.invoke({\"topic\": TOPIC})\n",
        "print(f\"   {result.content}\")\n",
        "\n",
        "print(\"\\nüí° Notice: Simple, direct fact - no special formatting or context\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üí¨ 2. Chat Template\n",
        "\n",
        "**Definition:** Template with multiple message types (system, user, assistant).\n",
        "\n",
        "**Characteristics:**\n",
        "- ‚úÖ **Role-based structure** - System message sets AI behavior, user message makes request\n",
        "- ‚úÖ **More controlled output** - System message guides the AI's approach\n",
        "- ‚úÖ **Professional responses** - AI adopts the specified personality/role\n",
        "- ‚ùå **More complex** - Requires understanding of message roles\n",
        "\n",
        "**When to use:** When you want to control the AI's persona, tone, or approach to answering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üí¨ Chat Template Demo\n",
        "\n",
        "print(\"üí¨ CHAT TEMPLATE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ChatPromptTemplate creates multiple messages with different roles\n",
        "template = ChatPromptTemplate([\n",
        "    (\"system\", \"You are a helpful teacher who explains things clearly\"),  # Sets AI behavior\n",
        "    (\"user\", \"Explain {topic} in simple terms\")  # User request with variable\n",
        "])\n",
        "\n",
        "print(f\"Variables: {template.input_variables}\")\n",
        "print(\"Template structure:\")\n",
        "print(\"  System: You are a helpful teacher who explains things clearly\")\n",
        "print(\"  User: Explain {topic} in simple terms\")\n",
        "\n",
        "# Connect template to LLM to see the different response style\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=100, openai_api_key=OPENAI_API_KEY)\n",
        "chain = template | model\n",
        "\n",
        "print(f\"\\nüìù Topic: {TOPIC}\")\n",
        "print(\"ü§ñ LLM Response:\")\n",
        "\n",
        "result = chain.invoke({\"topic\": TOPIC})\n",
        "print(f\"   {result.content}\")\n",
        "\n",
        "print(\"\\nüí° Notice: More educational tone due to 'teacher' system message\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üìö 3. Template with Conversation History\n",
        "\n",
        "**Definition:** Template that includes previous conversation context using `MessagesPlaceholder`.\n",
        "\n",
        "**Characteristics:**\n",
        "- ‚úÖ **Context awareness** - AI remembers previous conversation\n",
        "- ‚úÖ **More natural responses** - Builds on previous discussion\n",
        "- ‚úÖ **Personalized** - Takes user's expressed interests into account\n",
        "- ‚ùå **Complex setup** - Requires managing conversation history\n",
        "\n",
        "**When to use:** Building chatbots, ongoing conversations, or when context from previous exchanges matters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìö Template with Conversation History Demo\n",
        "\n",
        "print(\"üìö TEMPLATE WITH CONVERSATION HISTORY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# MessagesPlaceholder allows you to insert a list of previous messages\n",
        "template = ChatPromptTemplate([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    MessagesPlaceholder(\"history\"),  # This gets replaced with actual conversation\n",
        "    (\"user\", \"{question}\")\n",
        "])\n",
        "\n",
        "print(f\"Variables: {template.input_variables}\")  # Shows both 'history' and 'question'\n",
        "\n",
        "# Create conversation history about the topic\n",
        "history = [\n",
        "    HumanMessage(content=\"I'm learning about technology\"),\n",
        "    AIMessage(content=\"That's great! Technology is fascinating. What aspect interests you most?\"),\n",
        "    HumanMessage(content=f\"I'm particularly curious about {TOPIC} applications\")\n",
        "]\n",
        "\n",
        "print(\"\\nConversation context:\")\n",
        "for i, msg in enumerate(history, 1):\n",
        "    role = \"User\" if isinstance(msg, HumanMessage) else \"AI\"\n",
        "    print(f\"  {i}. {role}: {msg.content}\")\n",
        "\n",
        "# Connect template to LLM to see contextual response\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=120, openai_api_key=OPENAI_API_KEY)\n",
        "chain = template | model\n",
        "\n",
        "question = f\"Can you tell me more about {TOPIC}?\"\n",
        "print(f\"\\nüìù New Question: {question}\")\n",
        "print(\"ü§ñ LLM Response:\")\n",
        "\n",
        "result = chain.invoke({\n",
        "    \"history\": history,\n",
        "    \"question\": question\n",
        "})\n",
        "print(f\"   {result.content}\")\n",
        "\n",
        "print(\"\\nüí° Notice: Response references previous conversation context\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üìã 4. Complex Template with Detailed Instructions\n",
        "\n",
        "**Definition:** Template with sophisticated system instructions specifying format, style, and structure.\n",
        "\n",
        "**Characteristics:**\n",
        "- ‚úÖ **Highly structured output** - AI follows specific formatting rules\n",
        "- ‚úÖ **Professional quality** - More comprehensive and organized responses\n",
        "- ‚úÖ **Consistent format** - Same structure every time\n",
        "- ‚ùå **More complex to create** - Requires thinking about desired output format\n",
        "\n",
        "**When to use:** Professional reports, structured analysis, or when you need consistent, comprehensive responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìã Complex Template with Detailed Instructions Demo\n",
        "\n",
        "print(\"üìã COMPLEX TEMPLATE WITH DETAILED INSTRUCTIONS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create a sophisticated template with detailed instructions\n",
        "template = ChatPromptTemplate([\n",
        "    (\"system\", \"\"\"You are an expert technology consultant. When explaining topics:\n",
        "    1. Start with a clear definition\n",
        "    2. Provide 2-3 key applications\n",
        "    3. End with future implications\n",
        "    Format your response in a structured way.\"\"\"),\n",
        "    (\"user\", \"Provide a comprehensive overview of {topic}\")\n",
        "])\n",
        "\n",
        "print(\"Template structure:\")\n",
        "print(\"  System: Expert consultant with detailed formatting instructions\")\n",
        "print(\"  User: Provide a comprehensive overview of {topic}\")\n",
        "\n",
        "# Create the AI model and chain\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=200, openai_api_key=OPENAI_API_KEY)\n",
        "chain = template | model\n",
        "\n",
        "print(f\"\\nüìù Topic: {TOPIC}\")\n",
        "print(\"ü§ñ LLM Response:\")\n",
        "\n",
        "result = chain.invoke({\"topic\": TOPIC})\n",
        "print(f\"   {result.content}\")\n",
        "\n",
        "print(\"\\nüí° Notice: Structured, comprehensive response due to detailed system instructions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üéØ Template Style Comparison\n",
        "\n",
        "| Template Type | Response Style | Complexity | Best For |\n",
        "|---------------|----------------|------------|----------|\n",
        "| **üîó Basic** | Direct, factual | Low | Quick facts, simple information |\n",
        "| **üí¨ Chat** | Educational, clear | Medium | Teaching, explanations |  \n",
        "| **üìö With History** | Contextual, personalized | Medium | Ongoing conversations |\n",
        "| **üìã Complex** | Structured, comprehensive | High | Professional reports, analysis |\n",
        "\n",
        "## üí° Key Takeaways\n",
        "\n",
        "1. **Template structure dramatically affects response style** - same topic, very different outputs\n",
        "2. **Choose the right template for your use case:**\n",
        "   - Quick info ‚Üí Basic template\n",
        "   - Educational content ‚Üí Chat template with teacher role\n",
        "   - Conversations ‚Üí Templates with history  \n",
        "   - Professional analysis ‚Üí Complex instructions\n",
        "3. **System messages are powerful** - they set the AI's behavior and response style\n",
        "4. **Conversation history makes responses more natural** - context matters\n",
        "5. **Detailed instructions create consistent, structured output** - specify what you want\n",
        "\n",
        "## üöÄ Experiments to Try\n",
        "\n",
        "- Change the `TOPIC` variable at the top and re-run all cells\n",
        "- Modify the system messages to create different AI personas (doctor, lawyer, comedian)\n",
        "- Add more conversation history and see how it affects responses\n",
        "- Create your own complex instruction template for your specific use case\n",
        "- Combine techniques (e.g., role + conversation history + detailed instructions)\n",
        "\n",
        "## üéì Next Steps\n",
        "\n",
        "- Try these templates with your own real-world use cases\n",
        "- Experiment with different system message roles\n",
        "- Build templates for specific domains (customer support, education, analysis)\n",
        "- Learn about other LangChain components like output parsers and chains\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
