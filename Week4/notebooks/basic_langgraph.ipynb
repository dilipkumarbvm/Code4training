{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install python-dotenv if not already installed\n",
        "%pip install python-dotenv langgraph>=0.6.4 langchain-openai>0.3.29\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All required environment variables are set!\n",
            "\n",
            "Found .env file at: c:\\Users\\rregi\\Documents\\GitHub\\Code4Training\\Week4\\notebooks\\.env\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import required modules\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# You can check if required environment variables are set\n",
        "def validate_env_vars(required_vars):\n",
        "    missing_vars = []\n",
        "    for var in required_vars:\n",
        "        if os.getenv(var) is None:\n",
        "            missing_vars.append(var)\n",
        "    return missing_vars\n",
        "\n",
        "# List of required environment variables\n",
        "required_vars = ['OPENAI_API_KEY', 'OPENAI_MODEL']\n",
        "\n",
        "# Check for missing variables\n",
        "missing = validate_env_vars(required_vars)\n",
        "if missing:\n",
        "    print(f\"Warning: The following required environment variables are not set: {', '.join(missing)}\")\n",
        "else:\n",
        "    print(\"All required environment variables are set!\")\n",
        "\n",
        "# You can also load environment variables from a specific file\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# This will find the .env file automatically\n",
        "env_file = find_dotenv()\n",
        "print(f\"\\nFound .env file at: {env_file}\")\n",
        "\n",
        "# Reload environment variables (useful when .env file has changed)\n",
        "load_dotenv(override=True)  # override=True will reload all variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required typing utilities for type hints and annotations\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "# Import LangGraph components:\n",
        "# - StateGraph: Main class for building the conversation flow\n",
        "# - START: Special node marking the beginning of the graph\n",
        "# - END: Special node marking the end of the graph\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "# Import message handling utility\n",
        "#https://langchain-ai.github.io/langgraph/reference/graphs/#graph-definitions\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "# Define the structure of our conversation state\n",
        "class State(TypedDict):\n",
        "    \"\"\"\n",
        "    Defines the structure of the state that flows through our conversation graph.\n",
        "    \n",
        "    The state contains:\n",
        "    - messages: A list of conversation messages (both user and bot)\n",
        "    \n",
        "    The Annotated[list, add_messages] means:\n",
        "    - The field is a list\n",
        "    - When updating, use add_messages function to append new messages\n",
        "    - This prevents overwriting previous messages, maintaining conversation history\n",
        "    \"\"\"\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "# Initialize the graph builder with our State type\n",
        "# This creates a directed graph where:\n",
        "# - Nodes will be our processing steps (like the chatbot function)\n",
        "# - Edges define how messages flow between nodes\n",
        "# - The state (messages) flows through this graph structure\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# The graph will be used to:\n",
        "# 1. Take user input (START)\n",
        "# 2. Process it through our chatbot node\n",
        "# 3. Return the response (END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the LangChain function to initialize chat models\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# Initialize the Large Language Model (LLM) for our chatbot\n",
        "# Parameters explained:\n",
        "# - \"openai:gpt-4.1\" specifies:\n",
        "#   - Provider: OpenAI\n",
        "#   - Model: GPT-4.1 (latest version)\n",
        "# - This model will be used to generate responses in our chat application\n",
        "# - The model requires an OPENAI_API_KEY to be set in the environment variables\n",
        "#   (which we verified in the previous cell)\n",
        "llm = init_chat_model(\"openai:gpt-4.1\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the chatbot node function that processes messages in the graph\n",
        "def chatbot(state: State):\n",
        "    \"\"\"\n",
        "    This function defines how the chatbot processes messages in the LangGraph.\n",
        "    \n",
        "    Args:\n",
        "        state (State): Contains the current conversation state with a 'messages' key\n",
        "                      holding the list of all messages so far\n",
        "    \n",
        "    Returns:\n",
        "        dict: Returns a new state with the bot's response added to messages\n",
        "    \"\"\"\n",
        "    # llm.invoke() takes the current messages and generates a response\n",
        "    # state[\"messages\"] contains the conversation history\n",
        "    # The response is wrapped in a list to maintain the message chain format\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Example of what this function does:\n",
        "# Input state:  {\"messages\": [HumanMessage(content=\"Hello!\")]}\n",
        "# llm.invoke() generates response like: AIMessage(content=\"Hi! How can I help?\")\n",
        "# Output state: {\"messages\": [AIMessage(content=\"Hi! How can I help?\")]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mermaid Syntax:\n",
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tchatbot(chatbot)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> chatbot;\n",
            "\tchatbot --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n",
            "\n",
            "Graph Visualization:\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGsAAAD4CAIAAABkL4+2AAAAAXNSR0IArs4c6QAAFxZJREFUeJztnXlcU1e+wE/2hCyEBAxhERIWEdGIgbovqLWK1rpUrTPqUOfjUp3pa59Opy5tpX0+9am182q1tVp3a6tWR1ut2DpiqbghILiCLAKRJYFsN+tNMn+kpYxm5SSQ0PP9K8k99/Ljm5N7zz3n3PMj2Gw2gICA2N0BBD3IICzIICzIICzIICzIICxknxxFo8S1Slyntug0uAW3mQxWnxzW51DpRBKZEMImMzkkNpfM5Prg34c6RHOdsbocqyrXhnAoBsxCZ5HoTDKbRzEZ4APzC7gVaFpNBkyn11oYTJJOg4vTmOI0ZkQMrdPHJHSuRV1fqb96ttVktEYnMaOTmWGCzkfQjbQ1GusfYrJKjEojDJ3Mj05gdOIgXhtUtpjzT7SYTLb08eFBKu5ZWmXGkotyGp0wekZEaATFq329M/iwWPugSCsawBEmhHgfZ6Ajq9RV31anPsdOlDA938sLg1fPtTbXm4bPiOxshMFBwYknkXG0wS/wPCzvqcGyn9XNMvPAsXy48IKDkh8Ugt7UtKFsTwp7ZLDwrEKP2SRjw30RXnBQ/IOcHUocPNF9TXTfoq4o0cpl5t+VPgBA+vjwxsfGR7cxtyXdGGxrMt+/qRk2vYef+xwyYqbwzjWNSm52XcyNwfxvWkSSUJ8GFkyIJJxLJ1pcl3FlsL5SbzbbhOIe2HDxkKiEEKPeKqtydY/lyuCVM3LJmN/FxdcFA8aE/3xG7qKAU4PNdUabjcCPpvsnsKAhIpaO4zZ5g8lZAacGq8qwyN/x77cjQhGzqlzrbKtTg9V3tNHJXtzc+IRTp45u3ZrbiR1nzBjT3Nzoh4gAACA6mVl9x2mzxrFBTZuFziJ3fcdBRcW9Tuz15EkDhjmtI/DwhDQqnYSpLA63Ou4fVCtMuMmP48i1tVUHD35WXHydSqWlpKTNnv2nvn37r1y5qKysGACQl3fm00+PikSJp04dvX694P79chqNPnBgZk7OMoFACADIzV1Jo9F5PP6JE4dzcpbt27cDADB//pSRI8etXbvJHwGbjFa1wswMJT27yXEdxNQ4neWgtE8wGAx/+9tiCoW6Zcvnubkf2my2d999w2w2b9nyeXJy6oQJL54/f1MkSiwrK965c0taWvp7721ZuXJdY2ND+w+cSqVWV1fU19fm5m7Lzp6Rm7sNAHDw4Ld+0gcAYLDImBp3uMlxHdSpLQyWbwYAnqWh4bFKpZw+fa5IlAgAWLt20507JWazmUL5j4651NQBn332VUxMHJlMBgDo9boPPnjLaDTSaDQAQGNjw8cfH6RSqX4K8inoLJJ3Bq0WG5vnr+Cio3uHhnI3b35v3LjsAQOkqakDJJKMZ4uRSCSZrG7nzi0PHtzR63X2D1tb5UJhNAAgPj6xy/QBADh8mtXiePDH8a+YSCJoWp22gCCh0+lbt+7OzBz+zTeH33xz4cKFMy5dynu22JUrl3JzV/brJ9m27Yvz52++//5HHTYSulIfAECjMBKdnNUc18EQDsng8lYGktjY+MWL31iwYOmtW1fz8s5s2LA6Pj4hPj6hY5nvvz8lkWQsWLDU/larVXfYaOviCVN6zMLkOB5FcVwHmRyyXuP44g1PXV1NXt4Ze2UcNmzM6tUbAACVlfcBAAQCob2YWq0KC/ute+6nn350dsCOe/kJvQZnchzXNscGQ/lUMsVfYalUyq1bc/fs+Vgmq6+urjx69AsCgdC37wAAgFAYfe9eWWnpTZVKGR+fWFx8vby8BMfxY8cO2H+2DpvNUVExAID8/LyHD+/6KWYKlRjKdzwC5dggK4xk0FnaGo3+iCYtbeDrr6++cOHMq69OW7r0lQcP7mzevCs6OhYAkJ09w2q1rlq1vLa26tVXlw8cmLlmzV+nTBna1ta6YsU6sTjprbeWFBbmP3XA2Nj4rKyJ+/btsDcMfY5CZjQbLSGOGoOuevmvfd+q14P+ozwdcOnBlOUrmCxC5gTHKpzeF4vTmE01On8GFjQ0VutFaSxnW502myNiaEQCkNcbwmOcdnCtX/92UdFVh5usVgvRyfV/zZqNUukQd2F3hvLyknfffcPhJpPJ5KwBlJTUd9Omnc6O2fLYQKaA8CinjSdXY3UNj/RXvm0dOy/aWYHWVoXJ5Phc2X7z8CxcLo9O91e3Y2OjzOHnGKZlMh3XIwqFwudHODvgDwfqR00LF4qcBuzq1i06gUGlEZ480jmbocDjBVwPdmRklA+P1lCBMZhEF/rcjzSNnhlRVaLyYUzBRXWpeszMXq7LuDHIjaD0G8IpOPHEp4EFBz8dezJgOIfDd9PD4n7EPWEAMzKWVvyDq9GWnsetvJYoMU2U5r6X3tN5M+WFmiePTYPGB9yJzx8U5cljxLTUwR7Nm/F0HnXaUHYol1BwvOf/nH869iQsnOShPq/nDz4qw+5eU8elcaKTunoQqgtoeIjVlKv7D+V48uNtx+s5rCo5nv9Ns0FnTR8XwYvqIXNYFQ2G4h/lIWzS6OkRbi8dT9HJedSyKsPVswo9ZolOYkUnM3nCoFSpkBllFdqGCozBJA2dzHfd7nNGJw3akctM1eXaqnKMwSLrtDiDSaazyGwe1WTwV98iJFQ6UdNqNmhxvRZnsMgGDBf3Z4r6sVzctLkFymA7mNqibTNjagumxi1mm8nom+dJrFbrnj17Fi1a5JOjAQCoNCKJQmByyMxQMptLDuH4YDzSNwb9hMViGTZs2LVr17o7EFegp8JgQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhQQZhCdAnctLT04nEX77d9ghv3brVrUE5JkDrYFRUFOFXiEQikUgUCoXdHZRjAtSgVCrt+OOwWq1SqbRbI3JKgBqcN2+eQCBofysUCnNycro1IqcEqMHk5OTMzMz2t4MGDRKLxd0akVMC1CAAYO7cuZGRkQAAgUCwYMGC7g7HKYFrMCUlJT09HQCQkZGRlJTU3eE4xbvWjFqBN9cbtEq8a3L6KRSKc+fOTZo0ic/vilVaqHQSO4wUEUPn8LxYasELg0U/tjVUGQAg8KPpZh89xR5QUGhEeb2eQCDEJtLTs7ge7uWpwdICVX2lYciLAg/KBj1XTzf1Tmb0H87xpLBH58FHZVhVue53og8AMGSqoPK21kU2g454ZLD0sipt5O9rOdF+I/illz1a9M4jg401em5El66g3e2ERlAba/SelHRv0GSwkikEIsnvaz4HFGQKgUAAZqP7i0TgtgeDBWQQFmQQFmQQFmQQFmQQFmQQFmQQFmQQFmQQFmQQFmQQFmQQFmQQli41uGHD6pUroRb2PXnyy8mT/ZJfp9MEQR3sdFLjdqqrK3NyXvJdRP9BEBjsXFLjjjx4cMdHsTjAXwliCwvzd+zYLJc3JyT0mTbtlfHjJwMACAQihUItLb25ceNatVqZmJjy17+uSkzsY8+jdPz4wZs3C2trH/H5ESNGjPvjHxfR6fSnkhrbp3LV1z/eu3d7UdHVyMiouXP/PHr08+1/9NChXbW1VVwuLyGhz+uvr+bzww8c+PTw4d0AgBdeyDhx4l8slqdJHzyEtG7dOtclLLitJF+ZOizM84NeuXJp/fq3ly17a+LElxiMkJ07t8THJ8TFiQsKLj5+XNXW1vrqq8uysiZeuXLpxo2CyZNnAgCOHTtw9OjeJUv+e9KkaWlp6V9+ucdsNksk0gkTpl6/XiCVDtmx40hYGO/+/fKiosLKynszZvxx3LhJSmXr/v07n39+CovFvnXr2nvvvTl7ds7KlblpaekXLnz76NH9UaPGSyQZer1OqVScOPEvKtWL/AF3r7SlZ4WRyG6GN/xSBw8d2jVy5PixYycCADIzh2m1aq1WY9+kULS8/vqqkBAmAGDq1Nnbt2/S6/UMBmPmzHkjRoyNi/tletHt20U3b16ZP3/xU0e22Ww4jk+f/gd7vrb4+MQffvju8uULs2f/ad++HaNGjZ827RUAQP/+6YsXv/nOO//1hz9U2rMk+w/fG7TZbNXVlePHT2n/ZOnSFe2vxeJkuz4AQGhoGADAaDQwGAwKhXLzZuHmze9VV1fgOA4A6NUr8tmD25OcSqVDfz0Ct3dvkT3DWk1N5ejRE9pLJiamAAAePrzrb4O+v5IYjUar1eowWZ3NZiWRHCcT2L37H0eO7M7OnrF//+nz52/OmuV4spbNZiOTyQzGb4lwGYwQjUaFYVqj0dgxDZ79e2pPHe0/fF8HqVQqkUj0KnSbzXb27MmXX56fnT3d/sl/Ziv+DQKBgON4x3SCGKZlMtk0Gh0AoNf/NsKr02EAAB4vHO6/cY/v6yCRSExOTr19+7dZ47t2fbRnz8cudjGbzQaDvj1/oMFguHr1cvvWZ9MTV1dX2F9otZqGhsfR0bFkMjkpqe+9e7fby9hfi0RJ/k5w7Jf24JQpLxcVFR4/fqi09Obp019/881hsdjVBEAqlRoTE5eXd6axUaZSKT/8MHfAAKlarTQYDE8lNbYnidy795P6+sc4ju/d+4nVarWf/l58cVZBwcVTp45qtZri4uu7dm0bPHhEbGycPcFxS0tTYWG+/QzrW/xyLX7++SlKZevhw5/rdBifH7F48ZtZWRNd7/L22+s/+2zrwoXTGYyQ115bmZoquX7951mzxh448G129ox//ON/V61avnHjTrPZxGKxX3ppzooVf1aplPHxCWvXbrJfcyZMeFEub/766/07d24RCISDBg1ZuPAv9oMPGTLq4sVz69atOH78Ipvt0Ywsz3E/+81ksO57v2bmigCdxuw/jm9+tDBXTKG5OQMEwV1dgIMMwoIMwoIMwoIMwoIMwoIMwoIMwoIMwoIMwoIMwoIMwoIMwoIMwoIMwoIMwuLeIJVOtOA2Cx6IC/v4D9xkswHgtnvV0zoYGU9XyU2+CCxoUMlNwniGBwU9MzhwFLf8sgI6qmCi/LJCMsqjhQI8MihKYyZKWIX/bIIOLDi4crIxJYMdnxriSWEvVqoouaSsq9TbrCA8ltE1a310MVQ6qaVORySA3n0YHlZAr1dL0bThzXVGdau5a9b6sFqte/bsWbQIatqr51BohFA+tVcsjcX1z2opXY/FYhk2bNi1a9e6OxBXoPYgLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLMggLAH6RE56ejqR+Mu32x7hrVu3XO7UPQRoHYyKiiL8CpFIJBKJQqGwu4NyTIAalEqlHX8cVqtVKpV2a0ROCVCD8+bNEwh+SzgtFApzcnK6NSKnBKjB5OTkzMzM9reDBg0SiwN0IdgANQgAmDt3bmRkJABAIBAsWOB4ifRAIHANpqSkpKenAwAyMjKSklwtZ929+LI1Y9LblC0mTIPrNBbcZDXqYZ/iVigU586dmzRpEp/PhzwUjUEiUwkhbBKTTeb2olLpPlsl3QcGVS3m6jvYozLMbLLabIDOJNNZpNBwakCtJEChEdUKk0FrMWA4sAEagyjuzxT1Y4aGUyCPDGVQ2WL++bQc01h4Qnp0ErNXnEfLiwQCTTX6hgpM2WQIYZNGTA2H8dhJgzYruHisub5CP3BseEwfZqf/fLdTdx8rvSiP7cPIerkXoVMXhc4YVDwxfX+wKUkamjDQx2vcdxeVxerKIuWkHCFP4HVl9NpgRbH26jnFpMVx/sxY0Q3YrODsrtphU/iJEpZXO3pXcRtrjGWF6uwlPU0fAIBABJOXxpUWqJsee7c+lhd1sKoMK/lJNXpOVKciDBoufSkblMUV9fNowSMv6qC6Fb98sqXH6wMAjJkbdelYs1bpaS4YTw3mHW6avDQOIrBgYvKSuLxDni4y5pHBK98pesWFEEk97uTnBBKVwI9hXD3b6klh9wbNRuvtn5T9hnuRM7EHkDaSV3ypDTe7v0i4N/jzGYUky+85ywIQSRb/5zPuV110b/DedXVyRqiPogomkjO5966p3BZzY7C6HBOKPb2udwvbtn2wfPk8fxyZQACCOEbtPTepC90YrLqDRSUF8W0vJFFJzKpyzHUZNwZVcnNsH+/ucnoSMSlsZYvZdRlXiz2ajbbmOgOV4cd+7PPnT3/33Yna2kciUVJW1sSXXppj/3zWrHE5OcsViubDh3eHhDCfe27EsmV/Cw3lAgB0Ot2mTWtLSq6LxclTp84hdK5HxTPoIcTGGr3FbCNRnLbkXP15TI0zWP5Ksg0AuHjx3Icfvt+nT7/9+8/Mn7/k6NG9u3f/v30TmUz5+ut9NBr95Mn8zz8/Vlp648iR3fZNH330gUxWt3nzrnfe2VxRcbeoqNB/EQIAGCwSprG4KODKoE6NM1iOk+X6hHPnTkokGcuXv8XlhkmlQ+bPX3Ly5BGNRm3PVRobGz9nTk5ICDM8vFd6+mB7NneFoiU//8KcOTnJyak8Hn/RojfIZD9+xwAABouMqV3d4bkyaNRb+VF0FwVgsFqtd+/etqfCtjNwYCaO43fv3rbP9EhK6tu+icVi27Nwy2T1AIC4uAT75wQCwZ7p2X/wo+lGzFUddPUF0hhEhczgh6gAAMBkMuE4/sUX27/4YnvHz9Vqpf1Fx5S57R1I9q0dMz3bMxf7D0WDod9gV9dSVwZDOGS91pV+GOh0OoMRMmHCi8OHZ3X8PCbGVf8Fmx1qT3Dc/onBoHdRHh69FmdyXFlytY3JIeu1vk/4245IlIhhWokkw/7WaDS2tDTx+REudrEn2n3woDwpKcWusqTkhkDgxz43vdbCZLu6GLg6D1JohF6xdPhhX2fk5CwvKLh44cK3FoulrKx4/fq/r1q1zGx21f6KjIxKSUnbv3+nTFZvNBo3bFhNoVD9FB4AwIBZI+PpLpoy7lvU3HBK/X2trwP7BYlEun37oZKSG7Nnj1+z5i8Gg2Hdug8pFDdjPX//+/8kJfV97bVXpk8fxedHZGVN9N+QQ919DTfCzTfkppe/5g5WfFk1anbP75p2SP5RmXQcNy7FVc+AmzoYn8psqvHvqTpgsVmBvMHgWp8HedwJoO9znIc3VMmZTju4fvzx7Cef/J/DTSaTiUp1/CtYs2Zjx8YgJF99te+rr/Y53MThhKrVjjupPvpob+/eImfHfHBDmZLpfkDc/Vid2WTb807VrLcSnBXQ6XTtjbin0Go1LBbb4SYul9exWQeJVquxN7mfxWQyUqk0h5v4/AgXp92vNj5askFMIrs5y3o02ll4VmE2E/qN4Lkt2WMov9xKZ4DBE93/yx51bAzN5rfU6S0eDBr0DMxGq0Km90SfF6OdL8wTfPdpLVxgQcN3n9a+MD/Sw8KeGmRxyWNmRVz6UgYRWHDwryOy8XMFTI6nnVLezTxqemwqOC0fM7fHNg8vHm4YPSOiV4wX9znedfAKelMlI0O/3VlrDaDpqb7BarGd2VEjzeJ6pa+T8weVLeZz+xvFEk7ioB4yClpRpKoqVU9ZGMnh+3/+oB2bDVw61lJ7Hxs4Njy2bxAPRT2+qy25KI9PZY55OaJz99dQ86jVrXjBP+WaNpwXRYtOZAlEQTOPurFa11CBKRuNbB55xNRwdljnhwp8MJdfrTBX38GqyjGj3mq1AgaLRGeRA3UuP67XWggAMFhEcX+WKJXJ5sEOs/jyeRKz0aZsMWFqC6bGffI8iQ+xP0/C5JCZoaSwXlSyyy4/rwjQ54uDiMB9KixYQAZhQQZhQQZhQQZhQQZh+TfCSIGgaaTGpQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the graph structure using LangGraph's built-in visualization\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "# Get the Mermaid syntax\n",
        "print(\"Mermaid Syntax:\")\n",
        "print(graph.get_graph().draw_mermaid())\n",
        "\n",
        "# Display the graph as PNG\n",
        "print(\"\\nGraph Visualization:\")\n",
        "display(Image(graph.get_graph().draw_mermaid_png(\n",
        "    curve_style=CurveStyle.LINEAR,\n",
        "    node_colors=NodeStyles(\n",
        "        first=\"#90EE90\",  # Light green for start\n",
        "        last=\"#FFB6C1\",   # Light pink for end\n",
        "        default=\"#ADD8E6\"  # Light blue for other nodes\n",
        "    ),\n",
        "    wrap_label_n_words=9,\n",
        "    background_color=\"white\",\n",
        "    padding=10\n",
        ")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Empty initial state: {'messages': []}\n",
            "\n",
            "2. State after first user input: {'messages': [HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={})]}\n",
            "\n",
            "Complete state after bot response:\n",
            "- Contains both user and bot messages\n",
            "- Includes conversation metadata\n",
            "Raw state: {'messages': [HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={}, id='1e1b1429-9745-4dc8-9e13-da01e68731a6'), AIMessage(content=\"Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 13, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_799e4ca3f1', 'id': 'chatcmpl-C2R3KJgSjZ3CkI5NG9LTcyjMNAYcn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--905ad2f6-9d55-4fa0-848a-efcba1a4c688-0', usage_metadata={'input_tokens': 13, 'output_tokens': 29, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "\n",
            "3. First bot response: Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help. How can I assist you today?\n",
            "\n",
            "Breaking down the steps:\n",
            "1. All messages: [HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={}, id='1e1b1429-9745-4dc8-9e13-da01e68731a6'), AIMessage(content=\"Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 13, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_799e4ca3f1', 'id': 'chatcmpl-C2R3KJgSjZ3CkI5NG9LTcyjMNAYcn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--905ad2f6-9d55-4fa0-848a-efcba1a4c688-0', usage_metadata={'input_tokens': 13, 'output_tokens': 29, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "2. Last message: content=\"Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help. How can I assist you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 13, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_799e4ca3f1', 'id': 'chatcmpl-C2R3KJgSjZ3CkI5NG9LTcyjMNAYcn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--905ad2f6-9d55-4fa0-848a-efcba1a4c688-0' usage_metadata={'input_tokens': 13, 'output_tokens': 29, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "3. Just content: Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help. How can I assist you today?\n",
            "\n",
            "4. State after adding second user message:\n",
            "- Previous bot response remains in history\n",
            "- New user message added\n",
            "Message 1: User - Hello, how are you?\n",
            "Message 2: Bot - Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help. How can I assist you today?\n",
            "Message 3: User - What can you help me with?\n",
            "\n",
            "5. Second bot response: I can assist you with a wide variety of topics and tasks! Here are some examples:\n",
            "\n",
            "**Information and Research:**  \n",
            "- Answer questions about science, history, technology, or current events (up to my knowledge cutoff in June 2024).\n",
            "- Explain complex concepts in simple terms.\n",
            "- Suggest resources for further learning.\n",
            "\n",
            "**Writing and Communication:**  \n",
            "- Help write emails, essays, stories, and reports.\n",
            "- Proofread and edit text for grammar and clarity.\n",
            "- Generate creative ideas (e.g., for stories, blog posts, or projects).\n",
            "\n",
            "**Practical Tasks:**  \n",
            "- Assist with math problems, coding questions, and data analysis.\n",
            "- Give cooking tips, recipes, and meal planning advice.\n",
            "- Help with travel planning or organizing schedules.\n",
            "\n",
            "**Learning and Tutoring:**  \n",
            "- Explain math, science, and language concepts.\n",
            "- Create practice questions and quizzes for studying.\n",
            "\n",
            "**Personalized Recommendations:**  \n",
            "- Suggest books, movies, music, or podcasts.\n",
            "- Recommend productivity tools or study techniques.\n",
            "\n",
            "**General Guidance:**  \n",
            "- Offer advice on common challenges like time management, study strategies, or effective communication.\n",
            "\n",
            "If you have a specific task or question, just let me know!\n",
            "\n",
            "6. Final conversation state:\n",
            "Message 1: User - Hello, how are you?\n",
            "Message 2: Bot - Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help. How can I assist you today?\n",
            "Message 3: User - What can you help me with?\n",
            "Message 4: Bot - I can assist you with a wide variety of topics and tasks! Here are some examples:\n",
            "\n",
            "**Information and Research:**  \n",
            "- Answer questions about science, history, technology, or current events (up to my knowledge cutoff in June 2024).\n",
            "- Explain complex concepts in simple terms.\n",
            "- Suggest resources for further learning.\n",
            "\n",
            "**Writing and Communication:**  \n",
            "- Help write emails, essays, stories, and reports.\n",
            "- Proofread and edit text for grammar and clarity.\n",
            "- Generate creative ideas (e.g., for stories, blog posts, or projects).\n",
            "\n",
            "**Practical Tasks:**  \n",
            "- Assist with math problems, coding questions, and data analysis.\n",
            "- Give cooking tips, recipes, and meal planning advice.\n",
            "- Help with travel planning or organizing schedules.\n",
            "\n",
            "**Learning and Tutoring:**  \n",
            "- Explain math, science, and language concepts.\n",
            "- Create practice questions and quizzes for studying.\n",
            "\n",
            "**Personalized Recommendations:**  \n",
            "- Suggest books, movies, music, or podcasts.\n",
            "- Recommend productivity tools or study techniques.\n",
            "\n",
            "**General Guidance:**  \n",
            "- Offer advice on common challenges like time management, study strategies, or effective communication.\n",
            "\n",
            "If you have a specific task or question, just let me know!\n"
          ]
        }
      ],
      "source": [
        "# Example of how to use the graph with user input\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# Step 1: Start with empty state\n",
        "empty_state = {\n",
        "    \"messages\": []\n",
        "}\n",
        "print(\"1. Empty initial state:\", empty_state)\n",
        "\n",
        "# Step 2: First user message\n",
        "first_user_input = \"Hello, how are you?\"\n",
        "initial_state = {\n",
        "    \"messages\": [HumanMessage(content=first_user_input)]\n",
        "}\n",
        "print(\"\\n2. State after first user input:\", initial_state)\n",
        "\n",
        "# Step 3: Get bot's response to first message\n",
        "first_result = graph.invoke(initial_state)\n",
        "\n",
        "# Print the complete result to show the full state structure\n",
        "# This includes:\n",
        "# - The original user message (with metadata like ID)\n",
        "# - The bot's response (with metadata like token usage, model info)\n",
        "# - Additional metadata about the conversation\n",
        "print(\"\\nComplete state after bot response:\")\n",
        "print(\"- Contains both user and bot messages\")\n",
        "print(\"- Includes conversation metadata\")\n",
        "print(\"Raw state:\", first_result)\n",
        "\n",
        "# Print just the bot's response in a user-friendly format\n",
        "# Breaking down first_result[\"messages\"][-1].content:\n",
        "# 1. first_result[\"messages\"] - Gets the list of all messages\n",
        "# 2. [-1] - Gets the last message in the list (negative index counts from end)\n",
        "# 3. .content - Gets just the text content of that message\n",
        "#\n",
        "# Example structure:\n",
        "# first_result = {\n",
        "#     \"messages\": [\n",
        "#         HumanMessage(content=\"Hello, how are you?\"),  # index 0\n",
        "#         AIMessage(content=\"Hi! How can I help?\")      # index -1 (last)\n",
        "#     ]\n",
        "# }\n",
        "print(\"\\n3. First bot response:\", first_result[\"messages\"][-1].content)\n",
        "\n",
        "# Let's also print each part to see how we get to the content:\n",
        "print(\"\\nBreaking down the steps:\")\n",
        "print(\"1. All messages:\", first_result[\"messages\"])  # Shows full message list\n",
        "print(\"2. Last message:\", first_result[\"messages\"][-1])  # Shows last message with metadata\n",
        "print(\"3. Just content:\", first_result[\"messages\"][-1].content)  # Shows just the text\n",
        "\n",
        "# Step 4: Add second user message\n",
        "# Note: We need to include the previous messages to maintain conversation history\n",
        "second_user_input = \"What can you help me with?\"\n",
        "second_state = {\n",
        "    \"messages\": first_result[\"messages\"] + [HumanMessage(content=second_user_input)]\n",
        "}\n",
        "print(\"\\n4. State after adding second user message:\")\n",
        "print(\"- Previous bot response remains in history\")\n",
        "print(\"- New user message added\")\n",
        "for idx, msg in enumerate(second_state[\"messages\"]):\n",
        "    print(f\"Message {idx + 1}: {'User' if isinstance(msg, HumanMessage) else 'Bot'} - {msg.content}\")\n",
        "\n",
        "# Step 5: Get bot's response to second message\n",
        "second_result = graph.invoke(second_state)\n",
        "print(\"\\n5. Second bot response:\", second_result[\"messages\"][-1].content)\n",
        "\n",
        "# Step 6: Show final conversation state\n",
        "print(\"\\n6. Final conversation state:\")\n",
        "for idx, msg in enumerate(second_result[\"messages\"]):\n",
        "    print(f\"Message {idx + 1}: {'User' if isinstance(msg, HumanMessage) else 'Bot'} - {msg.content}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ee33363dced49699d2bb06a0d26928c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(Text(value='', description='Input:', layout=Layout(width='500px'), placeholder='â€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Basic LangGraph Chatbot\n",
        "# CONVERSATION WITH A BOT\n",
        "# Maintains conversation in memory\n",
        "# Import ipywidgets for interactive input\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display, clear_output\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# Create widgets for the chat interface\n",
        "text_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Type your message here...',\n",
        "    description='Input:',\n",
        "    layout={'width': '500px'}\n",
        ")\n",
        "send_button = widgets.Button(\n",
        "    description='Send',\n",
        "    button_style='primary',\n",
        "    layout={'width': '100px'}\n",
        ")\n",
        "output = widgets.Output()\n",
        "\n",
        "messages = []\n",
        "\n",
        "def on_send_button_clicked(b):\n",
        "    with output:\n",
        "        # clear_output()\n",
        "        # Get the input text\n",
        "        user_input = text_input.value\n",
        "        if not user_input.strip():  # Skip empty messages\n",
        "            return\n",
        "            \n",
        "        # Clear the input field\n",
        "        text_input.value = ''\n",
        "        \n",
        "        # Add user message to the state\n",
        "        messages.append(HumanMessage(content=user_input))\n",
        "        \n",
        "        # Display user message\n",
        "        print(f\"You: {user_input}\")\n",
        "        \n",
        "        # Run the graph\n",
        "        result = graph.invoke({\"messages\": messages})\n",
        "        \n",
        "        # Get the latest response and add it to messages\n",
        "        bot_response = result[\"messages\"][-1].content\n",
        "        messages.append(AIMessage(content=bot_response))\n",
        "        \n",
        "        # Display bot response\n",
        "        print(f\"\\nBot: {bot_response}\")\n",
        "\n",
        "# Connect the button click to the handler\n",
        "send_button.on_click(on_send_button_clicked)\n",
        "\n",
        "# Display the chat interface\n",
        "display(widgets.VBox([\n",
        "    widgets.HBox([text_input, send_button]),\n",
        "    output\n",
        "]))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "code4training",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
